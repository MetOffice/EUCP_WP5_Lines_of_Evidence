{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import iris\n",
    "from ascend import shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(data, ax, edge_color, fill_color, positions, widths):\n",
    "    bp = ax.boxplot(data, patch_artist=True, positions = positions, widths=widths, showfliers=False, whis=[10,90])\n",
    "    \n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "        if element == 'medians':\n",
    "            col = 'black'\n",
    "        else:\n",
    "            col = edge_color\n",
    "        plt.setp(bp[element], color=col)\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(facecolor=fill_color)       \n",
    "        \n",
    "    return bp\n",
    "\n",
    "\n",
    "def bxp(data, ax, colour, alpha, position, width, **kwargs):\n",
    "    bp = ax.bxp(data, patch_artist=True, positions=position, widths=width, showfliers=False, **kwargs)\n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "        if element == 'medians':\n",
    "            col = 'black'\n",
    "        else:\n",
    "            col = colour\n",
    "        plt.setp(bp[element], color=col)\n",
    "        plt.setp(bp[element], alpha=alpha)\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(facecolor=colour)\n",
    "        patch.set(alpha = alpha)   \n",
    "        \n",
    "    return bp\n",
    "\n",
    "    \n",
    "def create_x_points(ys, basex, offset):\n",
    "    xs = []\n",
    "    for i, v in enumerate(ys):\n",
    "        if i == 0:\n",
    "            xs.append(basex)\n",
    "            vm1 = v\n",
    "        else:\n",
    "            if abs(v - vm1) <= 1:\n",
    "                if xs[i-1] < basex:\n",
    "                    xs.append(basex + offset)\n",
    "                elif xs[i-1] == basex:\n",
    "                    xs[i-1] = basex - offset\n",
    "                    xs.append(basex + offset)\n",
    "                else:\n",
    "                    # previous version has been offset positively\n",
    "                    xs.append(basex - offset)\n",
    "            else:\n",
    "                xs.append(basex)\n",
    "            vm1 = v\n",
    "    \n",
    "    return xs\n",
    "\n",
    "def mask_wp2_atlas_data(cube, shp):\n",
    "    # mask wp2 data using shape file\n",
    "    \n",
    "    # approach varies depending on if cube is downloaded from WP2 atlas\n",
    "    # or direct from Glen's folders\n",
    "    if cube.ndim == 4:\n",
    "        # first get lat / lon mask over 2 dimensions\n",
    "        xy_mask = np.logical_not(shp.cube_intersection_mask(cube[0,:,:,0]))\n",
    "        # broadcast to 3d\n",
    "        xyp_mask = np.broadcast_to(xy_mask[:,:,np.newaxis], cube.shape[1:])\n",
    "        # broadcast to 4d\n",
    "        cube_mask = np.broadcast_to(xyp_mask, cube.shape)\n",
    "    else:\n",
    "        # 3 dimensional (lat, lon, percentile)\n",
    "        # get 2d mask\n",
    "        xy_mask = np.logical_not(shp.cube_intersection_mask(cube[:,:,0]))\n",
    "        # broadcast to 3d\n",
    "        cube_mask = np.broadcast_to(xy_mask[:,:,np.newaxis], cube.shape)\n",
    "\n",
    "    # apply to cube\n",
    "    # combine with existing mask\n",
    "    cube_mask = np.logical_or(cube_mask, cube.data.mask)\n",
    "    cube.data.mask = cube_mask\n",
    "\n",
    "    return cube\n",
    "\n",
    "\n",
    "def load_wp2_atlas(method, var, area, season):\n",
    "    # load netCDF file\n",
    "    base_path = \"/net/home/h02/tcrocker/code/EUCP_WP5_Lines_of_Evidence/weighting_data/WP2_atlas\"\n",
    "\n",
    "    # define region constraint if lat and lon supplied\n",
    "    if type(area) == list:\n",
    "        region = iris.Constraint(\n",
    "            longitude = lambda x: area[0] <= x <= area[1],\n",
    "            latitude = lambda x: area[2] <= x <= area[3]\n",
    "        )\n",
    "\n",
    "    bxp_obs = []\n",
    "    for data in [\"cons\", \"uncons\"]:\n",
    "        fname = f\"{base_path}/atlas_EUCP_{method}_{data}_{var}.nc\"\n",
    "        \n",
    "        cube = iris.load_cube(fname)\n",
    "\n",
    "        # extract shape / region\n",
    "        if type(area) == list:\n",
    "            cube = cube.extract(region)\n",
    "        else:\n",
    "            cube = mask_wp2_atlas_data(cube, area)\n",
    "\n",
    "        if season == \"JJA\":\n",
    "            # use first time point (JJA)\n",
    "            cube = cube[0]\n",
    "        elif season == \"DJF\":\n",
    "            cube = cube[1]\n",
    "        else:\n",
    "            raise ValueError(\"Only JJA and DJF available.\")\n",
    "\n",
    "        # area average\n",
    "        cube.coord(\"latitude\").units = \"degrees\"\n",
    "        cube.coord(\"latitude\").guess_bounds()\n",
    "        cube.coord(\"longitude\").units = \"degrees\"\n",
    "        cube.coord(\"longitude\").guess_bounds()\n",
    "        grid_areas = iris.analysis.cartography.area_weights(cube)\n",
    "        cube_mean = cube.collapsed([\"latitude\", \"longitude\"], iris.analysis.MEAN, weights=grid_areas)\n",
    "\n",
    "        # create boxplot stats object\n",
    "        if data == \"cons\":\n",
    "            label = method\n",
    "        else:\n",
    "            label = None\n",
    "\n",
    "        bxp_stats = {\n",
    "            \"whislo\": cube_mean.extract(iris.Constraint(percentile=10)).data.item(),\n",
    "            \"q1\": cube_mean.extract(iris.Constraint(percentile=25)).data.item(),\n",
    "            \"med\": cube_mean.extract(iris.Constraint(percentile=50)).data.item(),\n",
    "            \"q3\": cube_mean.extract(iris.Constraint(percentile=75)).data.item(),\n",
    "            \"whishi\": cube_mean.extract(iris.Constraint(percentile=90)).data.item(),\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "        bxp_obs.append(bxp_stats)\n",
    "\n",
    "    return bxp_obs\n",
    "\n",
    "def load_wp2_glen(var, area, season):\n",
    "    # Load WP2 constraint data from files in Glen's user space.\n",
    "    # define constraint if using a rectangle\n",
    "    if type(area) == list:\n",
    "        region = iris.Constraint(\n",
    "            longitude = lambda x: area[0] <= x <= area[1],\n",
    "            latitude = lambda x: area[2] <= x <= area[3]\n",
    "        )\n",
    "    \n",
    "    results = []\n",
    "    season = season.lower()\n",
    "    for d_type in [\"all\", \"prior\"]:\n",
    "        file_name = f\"/data/users/hadgh/eucp/data/v13/d23map/{var}Anom/{season}/{var}Anom_rcp85_eu_300km_W{d_type}-N600000-P21_cdf_b9514_20y_{season}_20401201-20601130.nc\"\n",
    "\n",
    "        cube = iris.load_cube(file_name)\n",
    "\n",
    "        # extract shape / region\n",
    "        if type(area) == list:\n",
    "            cube = cube.extract(region)\n",
    "        else:\n",
    "            cube = mask_wp2_atlas_data(cube, area)\n",
    "\n",
    "        grid_areas = iris.analysis.cartography.area_weights(cube)\n",
    "        cube_mean = cube.collapsed([\"latitude\", \"longitude\"], iris.analysis.MEAN, weights=grid_areas)\n",
    "\n",
    "        # create boxplot stats object\n",
    "        if d_type == \"all\":\n",
    "            label = \"UKCP constraint\"\n",
    "        else:\n",
    "            label = None\n",
    "\n",
    "        bxp_stats = {\n",
    "            \"whislo\": cube_mean.extract(iris.Constraint(percentile=10)).data.item(),\n",
    "            \"q1\": cube_mean.extract(iris.Constraint(percentile=25)).data.item(),\n",
    "            \"med\": cube_mean.extract(iris.Constraint(percentile=50)).data.item(),\n",
    "            \"q3\": cube_mean.extract(iris.Constraint(percentile=75)).data.item(),\n",
    "            \"whishi\": cube_mean.extract(iris.Constraint(percentile=90)).data.item(),\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "\n",
    "        results.append(bxp_stats)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def remove_institute_from_driver(driver_str):\n",
    "    # function to remove superfluous institute information from \n",
    "    # driving model supplied in CORDEX descriptions\n",
    "    INSTITUTES = [\n",
    "        'IPSL',\n",
    "        'NCC',\n",
    "        'MPI-M',\n",
    "        'CNRM-CERFACS',\n",
    "        'ICHEC',\n",
    "        'MOHC',\n",
    "        'KNMI',\n",
    "        'HCLIMcom',\n",
    "        'SMHI'\n",
    "    ]\n",
    "    # remove the institute bit from the \"driver\" string\n",
    "    new_str = driver_str\n",
    "    # loop through the institutes and remove them if found\n",
    "    for i in INSTITUTES:\n",
    "        i = '^' + i + '-'\n",
    "        new_str = re.sub(i, '', new_str)\n",
    "\n",
    "    if new_str == driver_str:\n",
    "        raise ValueError(f\"No institute found to remove from {driver_str}\")\n",
    "\n",
    "    return new_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# global variables to control everything\n",
    "RECIPE_RUN = 'recipe_GCM_and_RCM_ALP-3_20211125_150019'\n",
    "BASE_PATH = f'/home/h02/tcrocker/code/EUCP_WP5_Lines_of_Evidence/esmvaltool/esmvaltool_output/{RECIPE_RUN}/work/boxplots/main/'\n",
    "SEASON = 'JJA'\n",
    "# TODO setup dictionary linking RECIPE_RUN to area and variable.\n",
    "VAR = \"tas\"\n",
    "AREA = \"ALP-3\"\n",
    "# Path to my custom ClimWIP data, not needed for now.\n",
    "# CLIMWIP_PATH = '/home/h02/tcrocker/code/EUCP_WP5_Lines_of_Evidence/weighting_data/ClimWIP/pr_weighted_CMIP5_Romania_1995-2014_2041-2060.nc'\n",
    "\n",
    "# read data\n",
    "cmip5 = pd.read_csv(f'{BASE_PATH}CMIP5_{SEASON}.txt', sep=':', header=None)\n",
    "cmip6 = pd.read_csv(f'{BASE_PATH}CMIP6_{SEASON}.txt', sep=':', header=None)\n",
    "cordex = pd.read_csv(f'{BASE_PATH}CORDEX_{SEASON}.txt', sep=':', header=None)\n",
    "cpm = pd.read_csv(f'{BASE_PATH}CPM_{SEASON}.txt', sep=':', header=None)\n",
    "ukcp_g = pd.read_csv(f'{BASE_PATH}UKCP_gcm_{SEASON}.txt', sep=':', header=None)\n",
    "ukcp_r = pd.read_csv(f'{BASE_PATH}UKCP_rcm_{SEASON}.txt', sep=':', header=None)\n",
    "\n",
    "# List of models for Romania case study\n",
    "niculita_model_list = [\n",
    "    'RCA4 MPI-M-MPI-ESM-LR',\n",
    "    'RCA4 MOHC-HadGEM2-ES',\n",
    "    'RCA4 ICHEC-EC-EARTH',\n",
    "    'RCA4 CNRM-CERFACS-CNRM-CM5',\n",
    "    'REMO2009 MPI-M-MPI-ESM-LR',\n",
    "    'RACMO22E MOHC-HadGEM2-ES',\n",
    "    'RACMO22E ICHEC-EC-EARTH', \n",
    "    'HIRHAM5 ICHEC-EC-EARTH',\n",
    "    ]\n",
    "\n",
    "# List of CPM drivers from CORDEX to know which to plot as triangles\n",
    "# TODO this could be inferred from CPM_drivers dictionary and CPM data\n",
    "cpm_driver_list_CEE = [\n",
    "    'ICTP-RegCM4-7-0 MOHC-HadGEM2-ES',\n",
    "    'SMHI-HCLIM38-ALADIN ICHEC-EC-EARTH',\n",
    "]\n",
    "\n",
    "cpm_driver_list_ALP = [\n",
    "    'ALADIN63 CNRM-CERFACS-CNRM-CM5',\n",
    "    'CCLM4-8-17 ICHEC-EC-EARTH',\n",
    "    'HCLIMcom-HCLIM38-ALADIN ICHEC-EC-EARTH',\n",
    "    'REMO2015 MPI-M-MPI-ESM-LR',\n",
    "    'CCLM4-8-17 MPI-M-MPI-ESM-LR',\n",
    "    'ICTP-RegCM4-7-0 MOHC-HadGEM2-ES',\n",
    "    'KNMI-RACMO23E KNMI-EC-EARTH',\n",
    "    'MOHC-HadGEM3-GC3.1-N512 MOHC-HadGEM2-ES'\n",
    "]\n",
    "\n",
    "if area == \"ALP-3\":\n",
    "    cpm_driver_list = cpm_driver_list_ALP\n",
    "else:\n",
    "    cpm_driver_list = cpm_driver_list_CEE\n",
    "\n",
    "\n",
    "# map WP2 data to GCM group\n",
    "wp2_methods = {\n",
    "    \"ETHZ_CMIP6_ClimWIP\": \"CMIP6\",\n",
    "    \"ICTP_CMIP6_REA\": \"CMIP6\",\n",
    "    \"ICTP_CMIP5_REA\": \"CMIP5\",\n",
    "    \"UKMO_CMIP6_UKCP\": \"UKCP_GCM\"\n",
    "}\n",
    "\n",
    "# set colours\n",
    "colour_map = {\n",
    "    \"CMIP6\": \"tab:blue\",\n",
    "    \"CMIP5\": \"tab:orange\",\n",
    "    \"CORDEX\": \"tab:green\",\n",
    "    \"CPM\": \"tab:red\",\n",
    "    \"UKCP_GCM\": \"tab:purple\",\n",
    "}\n",
    "\n",
    "# create data frame of just CPM drivers\n",
    "cpm_driver_df = cordex[cordex[0].isin(cpm_driver_list)]\n",
    "# create subset of models used in paper (this is only needed for the Romania case study)\n",
    "nic_df = cordex[cordex[0].isin(niculita_model_list)]\n",
    "\n",
    "# CMIP5 CORDEX drivers can be inferred directly from CORDEX model names\n",
    "cordex_driver_list = list(\n",
    "    set(\n",
    "        [remove_institute_from_driver(n.split(' ')[1]) for n in cordex[0]]\n",
    "    )\n",
    ")\n",
    "cordex_driver_df = cmip5[cmip5[0].isin(cordex_driver_list)]\n",
    "\n",
    "# chuck everything in a dataframe for plotting\n",
    "plot_df = pd.DataFrame(\n",
    "    {\n",
    "        \"CMIP6\": cmip6[1],\n",
    "        \"CMIP5\": cmip5[1],\n",
    "        \"CORDEX Drivers\": cordex_driver_df[1],\n",
    "        \"CORDEX\": cordex[1],\n",
    "        \"Niclulită models\": nic_df[1],\n",
    "        \"CPM Drivers\": cpm_driver_df[1],\n",
    "        \"CPM\": cpm[1],\n",
    "        \"UKCP_GCM\": ukcp_g[1],\n",
    "        \"UKCP_RCM\": ukcp_r[1],\n",
    "        \"UKCP Drivers\": ukcp_g[ukcp_g[0].isin(ukcp_r[0])][1],\n",
    "    }\n",
    ")\n",
    "\n",
    "# my calculated ClimWIP data - not using for now\n",
    "# pr_cmip5_climwip = iris.load_cube(CLIMWIP_PATH)\n",
    "\n",
    "# Set area to extract for plots\n",
    "# area = shape.load_shp(\n",
    "#     '/net/home/h02/tcrocker/code/EUCP_WP5_Lines_of_Evidence/shape_files/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp',\n",
    "#     name = 'Romania'\n",
    "# )\n",
    "# ALP-3\n",
    "if AREA == \"ALP-3\"\n",
    "    area = [1, 17, 40, 50]\n",
    "else:\n",
    "# CEE-3\n",
    "    area = [18, 31, 41.5, 51.5]\n",
    "\n",
    "# load WP2 atlas constraint data\n",
    "constraint_data = {}\n",
    "for m in wp2_methods.keys():\n",
    "    constraint_data[m] = load_wp2_atlas(m, VAR, area, SEASON)\n",
    "\n",
    "# also load Glen's UKCP data\n",
    "constraint_data[\"UKMO_CMIP6_UKCP\"] = load_wp2_glen(VAR, area, SEASON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "# create figure and axes\n",
    "if AREA == \"Romania\" and VAR == \"pr\":\n",
    "    f, axs = plt.subplots(1,4, sharey=True, figsize=[19.2 ,  9.77], gridspec_kw={'width_ratios': [3, 2, 4, 1]})\n",
    "else:\n",
    "    f, axs = plt.subplots(1,3, sharey=True, figsize=[19.2 ,  9.77], gridspec_kw={'width_ratios': [3, 2, 4]})\n",
    "# f.suptitle(\"Projected % change in summer (JJA) rainfall for Romania. 2041-2060 vs 1995-2014. RCP8.5/ssp585\")\n",
    "# size of dots in swarm plots\n",
    "swarm_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First panel\n",
    "# plot GCM boxes\n",
    "axs[0].clear()\n",
    "\n",
    "# plot boxes with matplotlib\n",
    "box_plot([cmip6[1], cmip5[1], ukcp_g[1]], axs[0], \"black\", \"None\", [0, 1, 2], [0.5, 0.5, 0.5])\n",
    "# This is for my custom ClimWIP data, not using for now\n",
    "# box_plot([pr_cmip5_climwip[2].data], axs[0], \"grey\", \"lightgrey\", [1], [0.375])\n",
    "# axs[0].boxplot(\n",
    "#     x=[cmip6[1], cmip5[1], pr_cmip5_climwip[2].data],\n",
    "#     positions=[0, 1, 1],\n",
    "#     whis=[10,90],\n",
    "#     showfliers=False,\n",
    "#     widths=[0.5, 0.5, 0.375],\n",
    "#     patch_artist=True\n",
    "# )\n",
    "\n",
    "# or plot boxes with seaborn\n",
    "# sns.boxplot(data=plot_df[[\"CMIP6\", \"CMIP5\", \"UKCP_GCM\"]], ax=axs[0], color='white', fliersize=0)\n",
    "\n",
    "# plot dots\n",
    "sns.swarmplot(\n",
    "    data=plot_df[[\"CMIP6\", \"CMIP5\", \"UKCP_GCM\"]], ax=axs[0],\n",
    "    size=swarm_size, palette=[\"tab:blue\", \"tab:orange\", \"tab:purple\"],\n",
    "    alpha=0.75\n",
    "    )\n",
    "\n",
    "# last bits of formatting\n",
    "axs[0].axhline(linestyle=\":\", color=\"k\", alpha=0.5)\n",
    "plt.setp(axs[0].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "axs[0].set_title(\"GCMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot constrained ranges. 2nd panel\n",
    "axs[1].clear()\n",
    "for i, k in enumerate(constraint_data.keys()):\n",
    "    colour = colour_map[wp2_methods[k]]\n",
    "    # constrained\n",
    "    bxp([constraint_data[k][0]], axs[1], colour, 0.75, [i], 0.375)\n",
    "    # unconstrained\n",
    "    bxp([constraint_data[k][1]], axs[1], colour, 0.25, [i], 0.5)\n",
    "\n",
    "axs[1].axhline(linestyle=\":\", color=\"k\", alpha=0.5)\n",
    "plt.setp(axs[1].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "axs[1].set_title(\"Uncertainty estimates\\nfrom GCMs and observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third panel downscaled information\n",
    "axs[2].clear()\n",
    "sns.swarmplot(\n",
    "    data=plot_df[[\"CMIP5\", \"CORDEX\", \"CPM\", \"UKCP_GCM\", \"UKCP_RCM\"]], \n",
    "    ax=axs[2],\n",
    "    size=swarm_size,\n",
    "    palette=[\"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:purple\"]\n",
    ")\n",
    "# CORDEX drivers\n",
    "y = plot_df[\"CORDEX Drivers\"].dropna()\n",
    "x = create_x_points(y, 0.5, 0.05)\n",
    "axs[2].scatter(x, y, color=\"tab:orange\", marker=\">\", s=50)\n",
    "\n",
    "# CPM drivers\n",
    "y = plot_df[\"CPM Drivers\"].dropna()\n",
    "x = create_x_points(y, 1.5, 0.05)\n",
    "axs[2].scatter(x, y, color=\"tab:green\", marker=\">\", s=50)\n",
    "\n",
    "# Divider line for UKCP\n",
    "axs[2].axvline(2.5, color=\"lightgrey\")\n",
    "\n",
    "# UKCP drivers\n",
    "y = plot_df[\"UKCP Drivers\"].dropna()\n",
    "x = create_x_points(y, 3.5, 0.05)\n",
    "axs[2].scatter(x, y, color=\"tab:purple\", marker=\">\", s=50)\n",
    "\n",
    "# Final formatting etc.\n",
    "axs[2].axhline(linestyle=\":\", color=\"k\", alpha=0.5)\n",
    "plt.setp(axs[2].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "axs[2].set_title(\"Downscaled Projections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra panel if a case study\n",
    "if AREA == \"Romania\" and VAR == \"pr\":\n",
    "    axs[3].clear()\n",
    "    sns.swarmplot(\n",
    "        data = plot_df[\"Niclulită models\"],\n",
    "        ax=axs[3],\n",
    "        size=swarm_size,\n",
    "        palette=[\"tab:green\"]\n",
    "        )\n",
    "    axs[3].set_xticklabels([\"Niclulită models\"])\n",
    "    axs[3].axhline(linestyle=\":\", color=\"k\", alpha=0.5)\n",
    "    plt.setp(axs[3].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    axs[3].set_title(\"From study\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final figure spacing etc.\n",
    "# axs[0].set_ylabel(\"%\")\n",
    "plt.suptitle(f\"{AREA} {SEASON} {VAR}\")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.18, wspace=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6633e192c1a834d2fd65459fe5f8edb9aa82bc1737a4419b9833d7eca99ed278"
  },
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('2021_03_18-1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
